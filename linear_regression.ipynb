{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "M911F9k7SP_c",
    "outputId": "879f0754-bfcc-4ba1-daeb-88984fb9c37e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l2/bg92b_lx0ys_slmmxyqqrtrh0000gn/T/ipykernel_20865/1965950179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# perceptron learning is used as a learning technique here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#linear regression for x and y pairs\n",
    "# -> only 2D, every dim > 2 could be calculated with a perceptron\n",
    "# perceptron learning is used as a learning technique here\n",
    "\n",
    "from sklearn.utils.validation import check_random_state, check_X_y, check_array, check_is_fitted\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.multiclass import unique_labels \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "class LinearRegressor():\n",
    "    def __init__(self,X, y, weights = None, iterations = 50,random_state = None):\n",
    "        self.random_state = random_state\n",
    "        self.lr = 0.005\n",
    "        self.errors = []\n",
    "        self.iterations= iterations\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = weights\n",
    "        if self.weights == None:\n",
    "            self.random_state_ = check_random_state(self.random_state)\n",
    "            self.weights = self.random_state_.random_sample(np.size(self.X,1))\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        self.X,self.y = check_X_y(self.X,self.y)\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            rand_index = self.random_state_.randint(0, np.size(self.X,0))\n",
    "            x_ = self.X[rand_index]\n",
    "            y_ = self.y[rand_index]\n",
    "            y_hat = np.dot(self.weights,x_)\n",
    "            error = y_ - y_hat\n",
    "            \n",
    "            self.errors.append(error) \n",
    "\n",
    "            self.weights += error * x_ * self.lr\n",
    "\n",
    "            #print(self.w)\n",
    "              \n",
    "        return self\n",
    "\n",
    "    def predict(self, input):\n",
    "\n",
    "        prediction = np.dot(self.weights,input)\n",
    "        self.plot(input,prediction)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def plot(self,input=None,prediction=None):\n",
    "      \n",
    "        #2 values: bias and input\n",
    "        if np.size(self.X,1) == 2:\n",
    "            x = []\n",
    "        \n",
    "        if prediction != None and input != None:\n",
    "            x.append(input[1])\n",
    "            plt.scatter(input[1],prediction,c='b')\n",
    "            \n",
    "        for i in range(np.size(self.X,0)):\n",
    "            plt.scatter(self.X[i][1], self.y[i], c='r')\n",
    "\n",
    "        bias = self.weights[0]\n",
    "        w1 = self.weights[1]\n",
    "\n",
    "        for element in self.X:\n",
    "          x.append(element[1])\n",
    "\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "        y = w1*x + bias\n",
    "        plt.plot(x,y,'r')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "X = np.array([[1,5],[1,1],[1,3],[1,4]])\n",
    "y = np.array([5.95,2,4.1,5.12])\n",
    "b = LinearRegressor(X = X, y = y,weights=None,random_state = 13, iterations=15000)\n",
    "b.fit()\n",
    "b.plot()\n",
    "b.predict([1,5.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "linear regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
